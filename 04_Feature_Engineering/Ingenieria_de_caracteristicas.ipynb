{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder entrenar nuestros modelos de machine learning debemos crear un archivo de ingeniería de características.  \n",
    "\n",
    "\n",
    "\n",
    "Text Cleaning and Preparation: cleaning of special characters, downcasing, punctuation signs. possessive pronouns and stop words removal and lemmatization.\n",
    "Label coding: creation of a dictionary to map each category to a code.\n",
    "Train-test split: to test the models on unseen data.\n",
    "Text representation: use of TF-IDF scores to represent text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la ingeniería de características es el proceso de usar el conocimiento de dominio de los datos para crear características que hacen que los algoritmos de aprendizaje automático funcionen. Es como un arte, ya que requiere conocimiento del dominio y puede ser difícil crear características, pero puede ser fructífero para el algoritmo ML para predecir los resultados, ya que pueden estar relacionados con la predicción.\n",
    "\n",
    "fuente: https://towardsdatascience.com/natural-language-processing-nlp-for-machine-learning-d44498845d5b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from emoji import UNICODE_EMOJI\n",
    "from nltk import bigrams \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de la muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Esperanza\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4384: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  object.__getattribute__(self, name)\n",
      "C:\\Users\\Esperanza\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4385: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  return object.__setattr__(self, name, value)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../00_Dataset/clean_sentiment_labels_completo.csv\", sep=';')\n",
    "df.head()\n",
    "df.is_copy = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de los datos\n",
    "Una limpieza de los datos ha sido realizada tanto en el EDA como en la extracción. Sin embargo, aún hay algunos detalles que debemos depurar para poder hacer un buen análisis sobre nuestros datos.  \n",
    "\n",
    "Es  habitual la supresión de signos de puntuación pero en este caso nos ayudan a identificar la intensidad de los comentarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supresión de las columnas no necesarias***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>toxico</th>\n",
       "      <th>num_admir</th>\n",
       "      <th>num_may</th>\n",
       "      <th>num_may_esc</th>\n",
       "      <th>series_token</th>\n",
       "      <th>emojis</th>\n",
       "      <th>num_emoji</th>\n",
       "      <th>num_insultos</th>\n",
       "      <th>dir_23ps</th>\n",
       "      <th>score_emoji_tox</th>\n",
       "      <th>emphasize</th>\n",
       "      <th>filtered_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La etiqueta, cabrón</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['La', 'etiqueta', ',', 'cabrón']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['etiqueta,', 'cabrón']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hasta que un cabron trata a la lacra cómo se d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['Hasta', 'que', 'un', 'cabron', 'trata', 'a',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['cabron', 'trata', 'lacra', 'cómo', 'debe', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La edad no la pones eh cabrón</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['La', 'edad', 'no', 'la', 'pones', 'eh', 'cab...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['edad', 'no', 'pones', 'eh', 'cabrón']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y de un cabron solo puedes obtener cabronadas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['Y', 'de', 'un', 'cabron', 'solo', 'puedes', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['cabron', 'solo', 'puedes', 'obtener', 'cabro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eres más guiri que los irlandeses de aquí cabr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>['Eres', 'más', 'guiri', 'que', 'los', 'irland...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>['guiri', 'irlandeses', 'aquí', 'cabrón', 'xd']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texto  toxico  num_admir  \\\n",
       "0                                La etiqueta, cabrón       1          0   \n",
       "1  Hasta que un cabron trata a la lacra cómo se d...       1          0   \n",
       "2                      La edad no la pones eh cabrón       1          0   \n",
       "3      Y de un cabron solo puedes obtener cabronadas       1          0   \n",
       "4  Eres más guiri que los irlandeses de aquí cabr...       1          0   \n",
       "\n",
       "   num_may  num_may_esc                                       series_token  \\\n",
       "0        0          0.0                  ['La', 'etiqueta', ',', 'cabrón']   \n",
       "1        0          0.0  ['Hasta', 'que', 'un', 'cabron', 'trata', 'a',...   \n",
       "2        0          0.0  ['La', 'edad', 'no', 'la', 'pones', 'eh', 'cab...   \n",
       "3        0          0.0  ['Y', 'de', 'un', 'cabron', 'solo', 'puedes', ...   \n",
       "4        1          0.1  ['Eres', 'más', 'guiri', 'que', 'los', 'irland...   \n",
       "\n",
       "  emojis  num_emoji  num_insultos  dir_23ps  score_emoji_tox  emphasize  \\\n",
       "0    NaN          0             1         0              0.0        0.0   \n",
       "1    NaN          0             1         0              0.0        0.0   \n",
       "2    NaN          0             1         1              0.0        1.0   \n",
       "3    NaN          0             1         1              0.0        1.0   \n",
       "4    NaN          0             1         1              0.0        1.1   \n",
       "\n",
       "                                      filtered_words  \n",
       "0                            ['etiqueta,', 'cabrón']  \n",
       "1  ['cabron', 'trata', 'lacra', 'cómo', 'debe', '...  \n",
       "2            ['edad', 'no', 'pones', 'eh', 'cabrón']  \n",
       "3  ['cabron', 'solo', 'puedes', 'obtener', 'cabro...  \n",
       "4    ['guiri', 'irlandeses', 'aquí', 'cabrón', 'xd']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng=df[['texto', 'series_token','num_may_esc','num_insultos','score_emoji_tox','emphasize','toxico']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estandarización del texto**\n",
    "\n",
    "Se quitan los acentos y los números que no nos aportan información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unicodedata import normalize\n",
    "#Eliminamos acentos y números sueltos que no nos aportan información\n",
    "def estandarizacion(string):\n",
    "    res=re.sub(r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", normalize( \"NFD\", string), 0, re.I)\n",
    "    res=res.lower()\n",
    "    res=normalize( 'NFC', res)\n",
    "    res = re.sub(\" \\d+\", \" \", res)\n",
    "    res=normalize( 'NFC', res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Esperanza\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>series_token</th>\n",
       "      <th>num_may_esc</th>\n",
       "      <th>num_insultos</th>\n",
       "      <th>score_emoji_tox</th>\n",
       "      <th>emphasize</th>\n",
       "      <th>toxico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la etiqueta, cabron</td>\n",
       "      <td>['La', 'etiqueta', ',', 'cabrón']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasta que un cabron trata a la lacra como se d...</td>\n",
       "      <td>['Hasta', 'que', 'un', 'cabron', 'trata', 'a',...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>la edad no la pones eh cabron</td>\n",
       "      <td>['La', 'edad', 'no', 'la', 'pones', 'eh', 'cab...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y de un cabron solo puedes obtener cabronadas</td>\n",
       "      <td>['Y', 'de', 'un', 'cabron', 'solo', 'puedes', ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eres mas guiri que los irlandeses de aqui cabr...</td>\n",
       "      <td>['Eres', 'más', 'guiri', 'que', 'los', 'irland...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texto  \\\n",
       "0                                la etiqueta, cabron   \n",
       "1  hasta que un cabron trata a la lacra como se d...   \n",
       "2                      la edad no la pones eh cabron   \n",
       "3      y de un cabron solo puedes obtener cabronadas   \n",
       "4  eres mas guiri que los irlandeses de aqui cabr...   \n",
       "\n",
       "                                        series_token  num_may_esc  \\\n",
       "0                  ['La', 'etiqueta', ',', 'cabrón']          0.0   \n",
       "1  ['Hasta', 'que', 'un', 'cabron', 'trata', 'a',...          0.0   \n",
       "2  ['La', 'edad', 'no', 'la', 'pones', 'eh', 'cab...          0.0   \n",
       "3  ['Y', 'de', 'un', 'cabron', 'solo', 'puedes', ...          0.0   \n",
       "4  ['Eres', 'más', 'guiri', 'que', 'los', 'irland...          0.1   \n",
       "\n",
       "   num_insultos  score_emoji_tox  emphasize  toxico  \n",
       "0             1              0.0        0.0       1  \n",
       "1             1              0.0        0.0       1  \n",
       "2             1              0.0        1.0       1  \n",
       "3             1              0.0        1.0       1  \n",
       "4             1              0.0        1.1       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng['texto']=df_eng['texto'].apply(lambda lista: estandarizacion(lista))\n",
    "df_eng.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Redondeo del valor emphasize**\n",
    "\n",
    "Donde 70.55 es 71 y 70.4 es 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(1.020408))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Esperanza\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "df_eng.loc[:,'emphasize']=df_eng.loc[:,'emphasize'].map(lambda value: round(float(value),1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>series_token</th>\n",
       "      <th>num_may_esc</th>\n",
       "      <th>num_insultos</th>\n",
       "      <th>score_emoji_tox</th>\n",
       "      <th>emphasize</th>\n",
       "      <th>toxico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>la edad no la pones eh cabron</td>\n",
       "      <td>['La', 'edad', 'no', 'la', 'pones', 'eh', 'cab...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y de un cabron solo puedes obtener cabronadas</td>\n",
       "      <td>['Y', 'de', 'un', 'cabron', 'solo', 'puedes', ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eres mas guiri que los irlandeses de aqui cabr...</td>\n",
       "      <td>['Eres', 'más', 'guiri', 'que', 'los', 'irland...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>que es eso cabron</td>\n",
       "      <td>['Que', 'es', 'eso', 'cabron']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>alba “este hijo de puta de platini lo hicieron...</td>\n",
       "      <td>['Alba', '“', 'Este', 'hijo', 'de', 'puta', 'd...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texto  \\\n",
       "2                      la edad no la pones eh cabron   \n",
       "3      y de un cabron solo puedes obtener cabronadas   \n",
       "4  eres mas guiri que los irlandeses de aqui cabr...   \n",
       "7                                  que es eso cabron   \n",
       "8  alba “este hijo de puta de platini lo hicieron...   \n",
       "\n",
       "                                        series_token  num_may_esc  \\\n",
       "2  ['La', 'edad', 'no', 'la', 'pones', 'eh', 'cab...          0.0   \n",
       "3  ['Y', 'de', 'un', 'cabron', 'solo', 'puedes', ...          0.0   \n",
       "4  ['Eres', 'más', 'guiri', 'que', 'los', 'irland...          0.1   \n",
       "7                     ['Que', 'es', 'eso', 'cabron']          0.0   \n",
       "8  ['Alba', '“', 'Este', 'hijo', 'de', 'puta', 'd...          0.0   \n",
       "\n",
       "   num_insultos  score_emoji_tox  emphasize  toxico  \n",
       "2             1              0.0        1.0       1  \n",
       "3             1              0.0        1.0       1  \n",
       "4             1              0.0        1.1       1  \n",
       "7             1              0.0        1.0       1  \n",
       "8             1              0.0        1.0       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng[df_eng['emphasize']!=0.0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supresión de abreviaturas en el texto y conservión a minúsculas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un diccionario desde el csv que hemos creado\n",
    "path_ab='../00_Dataset/abreviaturas.csv'\n",
    "abrev = pd.read_csv(path_ab, sep=';')\n",
    "diccionario_abr=abrev.set_index('abreviatura').T.to_dict('dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parguela vete ya que estabamos contentos pensando que te habias muerto\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'parguela vete ya que estabamos contentos pensando que te habias muerto'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creación de una función en el que palabras como xa se convierten en para\n",
    "def delete_abrev(string):\n",
    "    words=string.split()\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in diccionario_abr.keys():\n",
    "            words[i] = diccionario_abr[words[i]]['significado'].lower()\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "\n",
    "#Comprobación del funcionamiento\n",
    "aux=df_eng.iloc[48]['texto']\n",
    "print(aux)\n",
    "delete_abrev(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Esperanza\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\Esperanza\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4384: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  object.__getattribute__(self, name)\n",
      "C:\\Users\\Esperanza\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4385: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  return object.__setattr__(self, name, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>series_token</th>\n",
       "      <th>num_may_esc</th>\n",
       "      <th>num_insultos</th>\n",
       "      <th>score_emoji_tox</th>\n",
       "      <th>emphasize</th>\n",
       "      <th>toxico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la etiqueta, cabron</td>\n",
       "      <td>['La', 'etiqueta', ',', 'cabrón']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasta que un cabron trata a la lacra como se d...</td>\n",
       "      <td>['Hasta', 'que', 'un', 'cabron', 'trata', 'a',...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>la edad no la pones eh cabron</td>\n",
       "      <td>['La', 'edad', 'no', 'la', 'pones', 'eh', 'cab...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y de un cabron solo puedes obtener cabronadas</td>\n",
       "      <td>['Y', 'de', 'un', 'cabron', 'solo', 'puedes', ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eres mas guiri que los irlandeses de aqui cabr...</td>\n",
       "      <td>['Eres', 'más', 'guiri', 'que', 'los', 'irland...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texto  \\\n",
       "0                                la etiqueta, cabron   \n",
       "1  hasta que un cabron trata a la lacra como se d...   \n",
       "2                      la edad no la pones eh cabron   \n",
       "3      y de un cabron solo puedes obtener cabronadas   \n",
       "4  eres mas guiri que los irlandeses de aqui cabr...   \n",
       "\n",
       "                                        series_token  num_may_esc  \\\n",
       "0                  ['La', 'etiqueta', ',', 'cabrón']          0.0   \n",
       "1  ['Hasta', 'que', 'un', 'cabron', 'trata', 'a',...          0.0   \n",
       "2  ['La', 'edad', 'no', 'la', 'pones', 'eh', 'cab...          0.0   \n",
       "3  ['Y', 'de', 'un', 'cabron', 'solo', 'puedes', ...          0.0   \n",
       "4  ['Eres', 'más', 'guiri', 'que', 'los', 'irland...          0.1   \n",
       "\n",
       "   num_insultos  score_emoji_tox  emphasize  toxico  \n",
       "0             1              0.0        0.0       1  \n",
       "1             1              0.0        0.0       1  \n",
       "2             1              0.0        1.0       1  \n",
       "3             1              0.0        1.0       1  \n",
       "4             1              0.0        1.1       1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sustitución de las abreviaciones en el dataset original\n",
    "df_eng.loc[:,'texto']=df_eng.loc[:,'texto'].map(lambda x: delete_abrev(x))\n",
    "df_eng.is_copy = False\n",
    "df_eng.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenización quitando las stopwords y los signos de puntuación**\n",
    "\n",
    "No siempre se han de quitar todas las stopwords ya que algunas como no si tienen peso en el algoritmo. En este caso eliminamos no del conjunto de palabras vacías y añadimos los signos de puntuación por tenerlos ya en cuenta en la etiqueta emphasize. \n",
    "\n",
    "Porqué eliminar las stopwords siempre no es una buena idea. Fuente: https://medium.com/@wilamelima/why-is-removing-stop-words-not-always-a-good-idea-c8d35bd77214\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cabron', 'problema', 'solucion']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopWords = stopwords.words('spanish')\n",
    "stopWords.remove('no')\n",
    "\n",
    "df_eng.loc[:,'filtered_words']=df_eng.loc[:,'texto'].map(lambda texto: texto.replace('.',''))\n",
    "df_eng.loc[:,'filtered_words']=df_eng.loc[:,'filtered_words'].map(lambda texto: texto.replace('?',''))\n",
    "df_eng.loc[:,'filtered_words']=df_eng.loc[:,'filtered_words'].map(lambda texto: texto.replace('!',''))\n",
    "df_eng.loc[:,'filtered_words']=df_eng.loc[:,'filtered_words'].map(lambda texto: texto.replace('¿',''))\n",
    "df_eng.loc[:,'filtered_words']=df_eng.loc[:,'filtered_words'].map(lambda texto: texto.replace(',',''))\n",
    "df_eng.loc[:,'filtered_words']=df_eng.loc[:,'filtered_words'].map(lambda texto: texto.replace('“',''))\n",
    "#Supresión de las stopword en castellano\n",
    "df_eng.loc[:,'filtered_words']=df_eng.loc[:,'filtered_words'].apply(lambda frase: [word.lower() for word in frase.split(' ') if word.lower() not in stopWords])\n",
    "\n",
    "df_eng.loc[6,'filtered_words']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmanization**\n",
    "\n",
    "Lemmatización es el proceso de convertir una palabra a su forma básica. La diferencia entre stemming y lemmatization es que la lematización considera el contexto y convierte la palabra a su forma básica significativa, mientras que stemming simplemente elimina los últimos caracteres, lo que a menudo conduce a significados incorrectos y errores de ortografía.\n",
    "\n",
    "fuente: https://www.machinelearningplus.com/nlp/lemmatization-examples-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'estudi'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prueba de funcionamiento\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "stemmer.stem(\"estudiando\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Estoy', 'estudiar', 'comer', 'funcionar', 'lemma', 'en', 'español', 'y', 'comer', 'no', 'funcionar', '.', 'Pero', 'que', 'decir', 'zampabollos']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "text1 = \"Estoy estudiando como funciona lemma en español y como no funciona.Pero que dices zampabollos \"\n",
    "res=[]\n",
    "for token in nlp(text1):\n",
    "    res.append(token.lemma_)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definición de la función que extrae el origen de la palabra\n",
    "def extraccion_lemma(text): \n",
    "    str1 = ' '.join(str(e) for e in text)\n",
    "    res=[]\n",
    "    for word in nlp(str1):\n",
    "        res.append(word.lemma_)\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la raiz no es tomada correctamente y no proporciona valor. Pero el lemma funciona suficientemente bien en castellano.  \n",
    "\n",
    "Algunos bugs como los presentados en https://github.com/explosion/spaCy/issues/2710 siguen sin ser solucionados. Palabras como 'estoy' no son traducidas a estar, 'como' es traducido por comer,.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng.loc[:,'filtered_words_lemm']=df_eng.loc[:,'filtered_words'].map(lambda text: extraccion_lemma(text) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividiendo el dataset en train, dev and test sets \n",
    "Pasos a tener en cuenta: \n",
    "- dev y test deben proceder de la misma distribución y se debe tomar de forma aleatoria del total del corpus. \n",
    "- dev y test deben tener el mismo tamaño. En nuestro caso dividiremos en train 70%, dev 15% y test 15%.\n",
    "- Se quiere tener unos datos no sesgados a la hora de realizar el algoritmo, para ello se cambia el orden de las filas pero inicializando una semilla que fije los resultados dependientes de una variable aleatoria. \n",
    "\n",
    "\n",
    "fuente: https://www.coursera.org/learn/machine-learning-projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>series_token</th>\n",
       "      <th>num_may_esc</th>\n",
       "      <th>num_insultos</th>\n",
       "      <th>score_emoji_tox</th>\n",
       "      <th>emphasize</th>\n",
       "      <th>toxico</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>filtered_words_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>toda la gente de alcasser se daba ostias habla...</td>\n",
       "      <td>['Toda', 'la', 'gente', 'de', 'Alcasser', 'se'...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[toda, gente, alcasser, daba, ostias, hablando...</td>\n",
       "      <td>[todo, gente, alcasser, dar, ostia, hablar, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>el carabinero es muy muy potente. sabe a “ahog...</td>\n",
       "      <td>['El', 'carabinero', 'es', 'muy', 'muy', 'pote...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[carabinero, potente, sabe, ahogadillas”, play...</td>\n",
       "      <td>[carabinero, potente, saber, ahogadillas, ”, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>se ha quedao dia de playa</td>\n",
       "      <td>['Se', 'ha', 'quedaO', 'día', 'de', 'playa']</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>[quedao, dia, playa]</td>\n",
       "      <td>[quedao, dia, playa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>quien es perroflauta?</td>\n",
       "      <td>['Quién', 'es', 'perroflauta', '?']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[perroflauta]</td>\n",
       "      <td>[perroflauta]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>jajajajajajaja otra ve por aqui? un abrazo cab...</td>\n",
       "      <td>['jajajajajajaja', 'otra', 've', 'por', 'aqui'...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[jajajajajajaja, ve, aqui, abrazo, cabestro]</td>\n",
       "      <td>[jajajajajajaja, ver, aqui, abrazar, cabestrar]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 texto  \\\n",
       "478  toda la gente de alcasser se daba ostias habla...   \n",
       "81   el carabinero es muy muy potente. sabe a “ahog...   \n",
       "77                           se ha quedao dia de playa   \n",
       "208                              quien es perroflauta?   \n",
       "319  jajajajajajaja otra ve por aqui? un abrazo cab...   \n",
       "\n",
       "                                          series_token  num_may_esc  \\\n",
       "478  ['Toda', 'la', 'gente', 'de', 'Alcasser', 'se'...     0.000000   \n",
       "81   ['El', 'carabinero', 'es', 'muy', 'muy', 'pote...     0.000000   \n",
       "77        ['Se', 'ha', 'quedaO', 'día', 'de', 'playa']     0.166667   \n",
       "208                ['Quién', 'es', 'perroflauta', '?']     0.000000   \n",
       "319  ['jajajajajajaja', 'otra', 've', 'por', 'aqui'...     0.000000   \n",
       "\n",
       "     num_insultos  score_emoji_tox  emphasize  toxico  \\\n",
       "478             0              0.0        1.0       0   \n",
       "81              0              0.0        1.0       0   \n",
       "77              0              0.0        0.2       0   \n",
       "208             0              0.0        1.0       0   \n",
       "319             1              0.0        1.0       0   \n",
       "\n",
       "                                        filtered_words  \\\n",
       "478  [toda, gente, alcasser, daba, ostias, hablando...   \n",
       "81   [carabinero, potente, sabe, ahogadillas”, play...   \n",
       "77                                [quedao, dia, playa]   \n",
       "208                                      [perroflauta]   \n",
       "319       [jajajajajajaja, ve, aqui, abrazo, cabestro]   \n",
       "\n",
       "                                   filtered_words_lemm  \n",
       "478  [todo, gente, alcasser, dar, ostia, hablar, ma...  \n",
       "81   [carabinero, potente, saber, ahogadillas, ”, p...  \n",
       "77                                [quedao, dia, playa]  \n",
       "208                                      [perroflauta]  \n",
       "319    [jajajajajajaja, ver, aqui, abrazar, cabestrar]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmod=df_eng.reindex(np.random.RandomState(seed=42).permutation(df_eng.index))\n",
    "dfmod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 5) (564,)\n",
      "(141, 5) (141,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "filtered_words          [pongo, castigo, cabezabuque]\n",
       "filtered_words_lemm    [poner, castigar, cabezabuque]\n",
       "num_insultos                                        1\n",
       "score_emoji_tox                                     0\n",
       "emphasize                                           1\n",
       "Name: 372, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=dfmod[['filtered_words','filtered_words_lemm', 'num_insultos', 'score_emoji_tox','emphasize']]\n",
    "y=dfmod['toxico']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "#everytime you run it without specifying random_state, you will get a different result\n",
    "print( X_train.shape, y_train.shape) \n",
    "print( X_test.shape, y_test.shape)\n",
    "X_train.iloc[240]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardado de los datos\n",
    "\n",
    "Pickle es utilizado cuando se tiene un conjunto de datos grande y se carga ese conjunto de datos masivos en la memoria cada vez que ejecuta el programa.Almacenarlo y recuperarlo será mucho más rápido, del orden de 50 - 100x, a veces mucho más dependiendo del tamaño.\n",
    "\n",
    "fuente: https://pythonprogramming.net/python-pickle-module-save-objects-serialization/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Almacenamiento del df del modelo\n",
    "pickle_out = open(\"dfmodelo.pickle\",\"wb\")\n",
    "pickle.dump(dfmod, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Almacenamiento del x_train\n",
    "pickle_out = open(\"X_train.pickle\",\"wb\")\n",
    "pickle.dump(X_train, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Almacenamiento del x_test\n",
    "pickle_out = open(\"X_test.pickle\",\"wb\")\n",
    "pickle.dump(X_test, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Almacenamiento del y_train\n",
    "pickle_out = open(\"y_train.pickle\",\"wb\")\n",
    "pickle.dump(y_train, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Almacenamiento del y_test\n",
    "pickle_out = open(\"y_test.pickle\",\"wb\")\n",
    "pickle.dump(y_test, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
